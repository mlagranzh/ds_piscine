{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 08. Exercise 03\n",
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`.\n",
    "3. Using, for example, `value_counts()` to check if the distribution of classes is similar in train and test.\n",
    "4. Use the additional parameter `stratify=` and check the distribution again, now it should be more or less similar in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials      hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0     -0.788667 -2.562352          4           0           0            0   \n",
       "1     -0.756764 -2.562352          4           0           0            0   \n",
       "2     -0.724861 -2.562352          4           0           0            0   \n",
       "3     -0.692958 -2.562352          4           0           0            0   \n",
       "4     -0.661055 -2.562352          4           0           0            0   \n",
       "...         ...       ...        ...         ...         ...          ...   \n",
       "1681  -0.533442  0.945382          3           0           0            0   \n",
       "1682  -0.629151  0.945382          3           0           1            0   \n",
       "1683  -0.597248  0.945382          3           0           1            0   \n",
       "1684  -0.565345  0.945382          3           0           1            0   \n",
       "1685  -0.533442  0.945382          3           0           1            0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0               0            0            0            0  ...              0   \n",
       "1               0            0            0            0  ...              0   \n",
       "2               0            0            0            0  ...              0   \n",
       "3               0            0            0            0  ...              0   \n",
       "4               0            0            0            0  ...              0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681            0            0            0            0  ...              0   \n",
       "1682            0            0            0            0  ...              0   \n",
       "1683            0            0            0            0  ...              0   \n",
       "1684            0            0            0            0  ...              0   \n",
       "1685            0            0            0            0  ...              0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681              0               0               0               0   \n",
       "1682              0               0               0               0   \n",
       "1683              0               0               0               0   \n",
       "1684              0               0               0               0   \n",
       "1685              0               0               0               0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                   0               0               0                0   \n",
       "1                   0               0               0                0   \n",
       "2                   0               0               0                0   \n",
       "3                   0               0               0                0   \n",
       "4                   0               0               0                0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681                0               0               0                1   \n",
       "1682                0               0               0                1   \n",
       "1683                0               0               0                1   \n",
       "1684                0               0               0                1   \n",
       "1685                0               0               0                1   \n",
       "\n",
       "      labname_project1  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "1681                 0  \n",
       "1682                 0  \n",
       "1683                 0  \n",
       "1684                 0  \n",
       "1685                 0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/dayofweek.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('dayofweek', axis=1)\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train exactly the same baseline models from the previous exercise and calculate the accuracies using the test dataset with stratification.\n",
    "2. Did all the models show the similar values of the metric? Which one has the largest difference comparing the current exercise and the previous? Put the answer to the markdown cell in the end of the section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(fit_intercept=False, random_state=21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=21, fit_intercept=False)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(fit_intercept=False, random_state=21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6272189349112426"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='poly', probability=True, random_state=21)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8431952662721893"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=16, random_state=21)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289940828402367"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=25, n_estimators=100, random_state=21)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could play with parameters of the model trying to achive a better accuracy on the test dataset, but it is a bad practice. It leads us again to overfitting. Test dataset is only for checking quality of a final model.\n",
    "\n",
    "But there is another way of solving the problem – crossvalidation. It does not use test dataset, but creates one more split of train dataset. Again, there are different ways of doing it, but the common thing is that there is a validation dataset that is used for hyperparameters optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `cross_val_score` with `cv=10` calculate the mean accuracy and standard deviation for every model that you used before (logreg with `solver='liblinear'`, SVC, decision tree, random forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(random_state=21), n_jobs=-1,\n",
       "             param_grid={'fit_intercept': [True, False],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=21)\n",
    "param_grid = {'fit_intercept': [True, False],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "cv_logreg = GridSearchCV(logreg, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "cv_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True, 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6390532544378699"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cv_logreg.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(random_state=21)\n",
    "param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'probability': [True, False]}\n",
    "\n",
    "cv_svc = GridSearchCV(svc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "cv_svc.fit(X_train, y_train)\n",
    "y_pred = cv_svc.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668639053254438"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=21)\n",
    "param_grid = {'max_depth': np.arange(3, 21)}\n",
    "\n",
    "cv_tree = GridSearchCV(tree, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "cv_tree.fit(X_train, y_train)\n",
    "cv_tree.best_params_\n",
    "y_pred = cv_tree.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=21), n_jobs=-1,\n",
       "             param_grid={'max_depth': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "       20]),\n",
       "                         'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=21)\n",
    "param_grid = {'n_estimators': np.arange(10, 200, 10),\n",
    "              'max_depth': np.arange(3, 21)}\n",
    "\n",
    "cv_forest = GridSearchCV(forest, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "cv_forest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_forest.best_params_\n",
    "y_pred = cv_forest.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and play a little bit with the parameters on cross-validation, find a good enough parameter or a combination of the parameters.\n",
    "2. Calculate the accuracy for the final model on the test dataset.\n",
    "3. Draw a plot that displays the top-10 most  important features for that model.\n",
    "4. Save the model using `joblib`.\n",
    "5. Load the model, make predictions for the test dataset and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45649126514511124"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=21)\n",
    "scores = cross_val_score(logreg, X, y, scoring='accuracy', cv=10)\n",
    "np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(coefs, features, n=10):\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    coefs /= coefs.sum()\n",
    "    indices = coefs.argsort()[::-1][:n]\n",
    "    ax.barh(np.arange(n), coefs[indices], color='mediumslateblue')\n",
    "    ax.set_yticks(np.arange(n))\n",
    "    ax.set_yticklabels(features[indices])\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_depth=20, n_estimators=60, random_state=21)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model.feature_importances_, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = joblib.load('best_model.joblib')\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
